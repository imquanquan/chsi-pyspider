#!/usr/bin/env python
# -*- encoding: utf-8 -*-
# Created on 2018-06-01 10:10:58
# Project: chsi

import os
import re
import time

from pyspider.libs.base_handler import *

BASE_URL = 'http://gaokao.chsi.com.cn'
FMT_URL = 'http://gaokao.chsi.com.cn/zsgs/zhangcheng/listVerifedZszc--method-index,lb-1,start-{}.dhtml'
SCHOOLS_FILE = 'schools.txt'
SCHOOL_RE = re.compile(r'<a href="(.*?)" target="_blank">(.*?)</a>')
HTML_HEAD = '''
<html xmlns="http://www.w3.org/1999/xhtml"><head>
<meta http-equiv="Content-Type" content="text/html; charset=utf8">
</head>
<body>
'''
HTML_TAIL = '''
</body>
</html>
'''
PATH = '/data'


os.chdir(PATH)
date = time.strftime("%Y%m%d", time.localtime())
if not os.path.exists(date):
    os.makedirs(date)    

    
class Handler(BaseHandler):
    crawl_config = {
    }

    @every(minutes=24 * 60)
    def on_start(self):
        for i in range(0, 28):
            if i == 0:
                url = 'http://gaokao.chsi.com.cn/zsgs/zhangcheng/listVerifedZszc--method-index,lb-1.dhtml'
            else:
                url = FMT_URL.format(i*100)
            self.crawl(url, callback=self.index_page)   
            
    @every(minutes=24 * 60)
    def index_page(self, response):
        items = SCHOOL_RE.findall(response.doc.html())
        for each in items:
            if not os.path.exists(each[1]):
                os.makedirs(date+'/'+each[1]) 
            self.crawl(each[0], callback=self.url_page, save={'school_name': each[1]})

    @every(minutes=24 * 60)
    def url_page(self, response):
        for each in response.doc('.right:first tr').items():
            for a in each('td a').items():
                self.crawl(a.attr.href, callback=self.detail_page, save={'school_name': response.save['school_name']})
    
    @every(minutes=24 * 60)
    def detail_page(self, response):
        name = response.doc('h2').text()
        mess = HTML_HEAD + str(response.doc('.content')) + HTML_TAIL
        with open(date+'/'+response.save['school_name']+'/'+name+'.html', 'w') as f:
            f.write(mess)
